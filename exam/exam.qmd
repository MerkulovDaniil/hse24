---
format: 
    pdf:
        pdf-engine: xelatex
        include-in-header: ./header.tex  # Custom LaTeX commands and preamble
---

# Определения и формулировки

1. Положительно определённая матрица.
1. Евклидова норма вектора.
1. Неравенство треугольника для нормы.
1. $p$-норма вектора.
1. Как выглядит единичный шар в $p$ - норме на плоскости для $p=1,2,\infty$?
1. Норма Фробениуса для матрицы.
1. Спектральная норма матрицы.
1. Скалярное произведение двух векторов.
1. Скалярное произведение двух матриц, согласованное с нормой Фробениуса.
1. Собственные значения матрицы. Спектр матрицы.
1. Связь спектра матрицы и её определенности.
1. Спектральное разложение матрицы.
1. Сингулярное разложение матрицы.
1. Связь определителя и собственных чисел для квадратной матрицы.
1. Связь следа и собственных чисел для квадратной матрицы.
1. Линейная сходимость последовательности. 
1. Сублинейная сходимость последовательности. 
1. Сверхлинейная сходимость последовательности. 
1. Квадратичная сходимость последовательности.
1. Тест корней для определения скорости сходимости последовательности.
1. Тест отношений для определения скорости сходимости последовательности.
1. Унимодальная функция.
1. Метод дихотомии.
1. Метод золотого сечения.
1. Метод параболлической интерполяции.
1. Условие достаточного убывания для неточного линейного поиска.
1. Условия Гольдштейна для неточного линейного поиска.
1. Условие ограничения на кривизну для неточного линейного поиска.
1. Градиент функции $f(x): \mathbb{R}^n \to \mathbb{R}$.
1. Гессиан функции $f(x): \mathbb{R}^n \to \mathbb{R}$.
1. Якобиан функции $f(x): \mathbb{R}^n \to \mathbb{R}^m$.
1. Формула для аппроксимации Тейлора первого порядка $f^I_{x_0}(x)$ функции $f(x): \mathbb{R}^n \to \mathbb{R}$ в точке $x_0$.
1. Формула для аппроксимации Тейлора второго порядка $f^{II}_{x_0}(x)$ функции $f(x): \mathbb{R}^n \to \mathbb{R}$ в точке $x_0$.
1. Связь дифференциала функции $df$ и градиента $\nabla f$ для функции $f(x): \mathbb{R}^n \to \mathbb{R}$.
1. Связь второго дифференциала функции $d^2f$ и гессиана $\nabla^2 f$ для функции $f(x): \mathbb{R}^n \to \mathbb{R}$.
1. Формула для приближенного вычисления производной функции $f(x): \mathbb{R}^n \to \mathbb{R}$ по $k$-ой координате с помощью метода конечных разностей.
1. Пусть $f = f(x_1(t), \ldots, x_n(t))$. Формула для вычисления $\frac{\partial f}{\partial t}$ через $\frac{\partial x_i}{\partial t}$ (Forward chain rule).
1. Пусть $L$ - функция, возвращающая скаляр, а $v_k$ - функция, возвращающая вектор $x \in \mathbb{R}^t$. Формула для вычисления $\frac{\partial L}{\partial v_k}$ через $\frac{\partial L}{\partial x_i}$ (Backward chain rule).
1. Идея Хатчинсона для оценки следа матрицы с помощью matvec операций.
1. Афинное множество. Афинная комбинация. Афинная оболочка.
1. Выпуклое множество. Выпуклая комбинация. Выпуклая оболочка.
1. Конус. Выпуклый конус. Коническая комбинация. Коническая оболочка.
1. Внутренность множества. 
1. Относительная внутренность множества.
1. Сумма Минковского.
1. Любые 2 операции с множествами, сохраняющие выпуклость.
1. Выпуклая функция.
1. Строго выпуклая функция.
1. Надграфик функции $f(x): \mathbb{R}^n \to \mathbb{R}$.
1. Множество подуровней функции $f(x): \mathbb{R}^n \to \mathbb{R}$.
1. Дифференциальный критерий выпуклости первого порядка.
1. Дифференциальный критерий выпуклости второго порядка.
1. Связь выпуклости функции и её надграфика.
1. $\mu$-сильно выпуклая функция.
1. Дифференциальный критерий сильной выпуклости первого порядка.
1. Дифференциальный критерий сильной выпуклости второго порядка.
1. Любые 2 операции с функциями, сохраняющие выпуклость.
1. Теорема Тейлора.
1. Необходимые условия локального экстремума.
1. Достаточные условия локального экстремума.
1. Общая задача математического программирования. Функция Лагранжа.
1. Теорема Каруша - Куна - Таккера в форме необходимых условий решения задачи математического программирования.
1. Условие Слейтера.
1. Задача выпуклого программирования.
1. Двойственная функция в задаче математического программирования.
1. Двойственная задача для задачи математического программирования.
1. Сильная двойственность. Зазор двойственности.
1. Локальный анализ чувствительности с помощью множителей Лагранжа.
1. Задача линейного программирования. Задача линейного программирования в стандартной форме.
1. Возможные случаи двойственности в задаче линейного программирования.
1. Симплекс метод.
1. Нахождение первоначальной угловой точки с помощью двухфазного симплекс метода.
1. Сходимость симплекс метода.
1. Показать, что направление антиградиента - направление наискорейшего локального убывания функции.
1. Дифференциальное уравнение градиентного потока.
1. Метод градиентного спуска.
1. Наискорейший спуск.
1. Липшицева парабола для гладкой функции.
1. Размер шага наискорейшего спуска для квадратичной функции.
1. Характер сходимости градиентного спуска к локальному экстремуму для гладких невыпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Характер сходимости градиентного спуска для гладких выпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Характер сходимости градиентного спуска для гладких и сильно выпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Связь спектра гессиана с константами сильной выпуклости и гладкости функции.
1. Условие Поляка-Лоясиевича (градиентного доминирования) для функций.
1. Сходимость градиентного спуска для сильно выпуклых квадратичных функций. Оптимальные гиперпараметры.
1. Связь PL-функций и сильно выпуклых функций. 
1. Привести пример выпуклой, но не сильно выпуклой задачи линейных наименьших квадратов (возможно, с регуляризацией).
1. Привести пример сильно выпуклой задачи линейных наименьших квадратов (возможно, с регуляризацией).
1. Привести пример выпуклой негладкой задачи линейных наименьших квадратов (возможно, с регуляризацией).
1. Субградиент. Субдифференциал.
1. Субградиентный метод.
1. Характер сходимости субградиентного метода для негладких выпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Нижние оценки для гладкой выпуклой оптимизации с помощью методов первого порядка в терминах $\mathcal{O}$ от числа итераций метода.
1. Отличие ускоренной и неускоренной линейной сходимости для методов первого порядка.
1. Метод тяжелого шарика (Поляка).
1. Ускоренный градиентный метод Нестерова для выпуклых гладких функций.
1. Ускоренный градиентный метод Нестерова для сильно выпуклых гладких функций.
1. Проекция.
1. Достаточное условие существования проекции точки на множество.
1. Достаточное условие единственности проекции точки на множество.
1. Метод проекции градиента.
1. Критерий проекции точки на выпуклое множество (Неравенство Бурбаки-Чейни-Гольдштейна).
1. Проекция как нерастягивающий оператор.
1. Метод Франк-Вульфа.
1. Характер сходимости метода проекции градиента для гладких выпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Характер сходимости метода проекции градиента для гладких сильно выпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Характер сходимости метода Франк-Вульфа для гладких выпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Характер сходимости метода Франк-Вульфа для гладких сильно выпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. $A$-сопряженность двух векторов. $A$-ортогональность. Скалярное произведение $\langle \cdot, \cdot \rangle_A$.
1. Процедура ортогонализации Грама-Шмидта.
1. Метод сопряженных направлений.
1. Метод сопряженных градиентов.
1. Зависимость сходимости метода сопряженных градиентнов от спектра матрицы.
1. Характер сходимости метода сопряженных градиентов в терминах $\mathcal{O}$ от числа итераций метода.
1. Метод Поляка-Рибьера.
1. Метод Ньютона.
1. Сходимость метода Ньютона для квадратичной функции.
1. Характер сходимости метода Ньютона для сильно выпуклых гладких функций - куда и как сходится.
1. Демпфированный метод Ньютона.
1. Идея квазиньютоновских методов. Метод SR-1.
1. Нижние оценки для негладкой выпуклой оптимизации с помощью методов первого порядка в терминах $\mathcal{O}$ от числа итераций метода.
1. Проксимальный оператор.
1. Оператор проекции как частный случай проксимального оператора.
1. Характер сходимости проксимального градиентного метода для гладких выпуклых функций $f$ в терминах $\mathcal{O}$ от числа итераций метода.
1. Характер сходимости проксимального градиентного метода для гладких сильно выпуклых функций $f$ в терминах $\mathcal{O}$ от числа итераций метода.
1. Аналитическое выражение для $\text{prox}_{\lambda \|x\|_1}$.
1. Аналитическое выражение для $\text{prox}_{\frac{\mu}{2} \|x\|_2^2}$.
1. Проксимальный оператор как нерастягивающий оператор.
1. Характер сходимости ускоренного проксимального градиентного метода для гладких выпуклых функций $f$ в терминах $\mathcal{O}$ от числа итераций метода.
1. Метод стохастического градиентного спуска.
1. Идея мини-батча для метода стохастического градиентного спуска. Эпоха.
1. Характер сходимости стохастического градиентного спуска для гладких выпуклых функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Характер сходимости стохастического градиентного спуска для гладких PL-функций в терминах $\mathcal{O}$ от числа итераций метода.
1. Характер работы стохастического градиентного спуска с постоянным шагом для гладких PL-функций.
1. Основная идея методов уменьшения дисперсии.
1. Метод SVRG.
1. Метод SAG.
1. Метод Adagrad.
1. Метод RMSProp.
1. Метод Adadelta.
1. Метод Adam.
1. Идея проекции функции потерь нейронной сети на прямую, плоскость.
1. Grokking.
1. Double Descent.
1. Взрыв/Затухание градиентов при обучении глубоких нейронных сетей.
1. Идея gradient checkpointing.
1. Идея аккумуляции градиентов.
1. Зачем увеличивать батч при обучении больших нейросетевых моделей. Warmup. 
1. Метод двойственного градиентного подъема.
1. Связь константы сильной выпуклости $f$ и гладкости $f^*$.
1. Идея dual decomposition.
1. Метод двойственного градиентного подъема для линейных ограничений-неравенств.
1. Метод модифицированной функции Лагранжа.
1. Метод ADMM.
1. Формулировка задачи линейных наименьших квадратов с $\ell_1$ регуляризацией в форме ADMM.
1. Формулировка задачи поиска точки на пересечении двух выпуклых множеств в форме ADMM.

# Теоремы с доказательствами

1. Критерий положительной определенности матрицы через знаки собственных значений матрицы.
1. Автоматическое дифференцирование. Вычислительный граф. Forward/ Backward mode (в этом вопросе нет доказательств, но необходимо подробно описать алгоритмы).
1. Метод дихотомии и золотого сечения для унимодальных функций. Скорость сходимости.
1. Базовые операции, сохраняющие выпуклость множеств: пересечение бесконечного числа множеств, линейная комбинация множеств, образ афинного отображения.
1. Неравенство Йенсена для выпуклой функции и выпуклой комбинации точек.
1. Выпуклость надграфика как критерий выпуклости функции.
1. Дифференциальный критерий сильной выпуклости первого порядка.
1. Дифференциальный критерий сильной выпуклости второго порядка.
1. Необходимые условия безусловного экстремума.
1. Достаточные условия безусловного экстремума.
1. Формулировка симплекс метода для задачи линейного программирования в стандартной форме. Теорема о проверке оптимальности решения.
1. Теорема сходимости градиентного спуска для гладких выпуклых функций. 
1. Теорема сходимости градиентного спуска для гладких PL функций. 
1. Теорема сходимости градиентного спуска для сильно выпуклых квадратичных функций. Оптимальные гиперпараметры.
1. Теорема сходимости субградиентного метода для выпуклых функций. Сходимость метода для разных стратегий выбора шага: постоянный размер шага $\alpha_k = \alpha$; Обратный квадратный корень $\frac{R}{G\sqrt{k}}$; Обратный $\frac1k$; Размер шага Поляка: $\alpha_k = \frac{f(x^k) - f^*}{\|g_k\|_2^2}$.
1. Теорема о сходимости метода тяжелого шарика для сильно выпуклой квадратичной задачи.
1. Теорема о сходимости метода проекции градиента для выпуклой гладкой функции.
1. Теорема о сходимости метода проекции градиента для сильно выпуклой гладкой функции.
1. Теорема о сходимости метода Франк-Вульфа для выпуклой гладкой функции.
1. Доказательство сходимости метода сопряженных градиентов и вывод формулы.
1. Теорема сходимости метода Ньютона для сильно выпуклых функций с липшицевым гессианом.
1. Вывод формул обновления оценок обратного гессиана и гессиана квазиньютоновских методов SR-1, DFP, BFGS.
1. Теорема о сходимости проксимального градиентного для выпуклой гладкой функции $f$.
1. Теорема о сходимости проксимального градиентного для сильно выпуклой гладкой функции $f$.
1. Теорема о сходимости стохастического градиентного спуска в гладком PL-случае. 