[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Optimization for ML",
    "section": "",
    "text": "Optimization for ML\n\nCourse for 3rd year students of CS department at HSE university. 1 lecture + 1 seminar per week.\nThe course covers convex, non-convex, continuous optimization topics, especially motivated by problems and applications in Machine Learning. Various topics are covered, from fundamental materials to recent research.\nDescription of the course.\n\n                        \n                                            \n\n\nTeam\n\n\n    \n        \n            \n                \n                  \n                    \n                  \n                  \n                    \n                      Daniil Merkulov\n                    \n                    Instructor\n                  \n                \n              \n        \n            \n                \n                  \n                    \n                  \n                  \n                    \n                      Farukh Yaushev\n                    \n                    Seminarist\n                  \n                \n              \n        \n            \n                \n                  \n                    \n                  \n                  \n                    \n                      Kirill Nikorov\n                    \n                    Seminarist\n                  \n                \n              \n        \n            \n                \n                  \n                    \n                  \n                  \n                    \n                      Michael Persiianov\n                    \n                    Seminarist\n                  \n                \n              \n        \n            \n                \n                  \n                    \n                  \n                  \n                    \n                      Arina Kosovskaia\n                    \n                    Senior Assistant\n                  \n                \n              \n        \n            \n                \n                  \n                    \n                  \n                  \n                    \n                      Daniil Radushev\n                    \n                    Assistant\n                  \n                \n              \n        \n            \n                \n                  \n                    \n                  \n                  \n                    \n                      Maria Medvedeva\n                    \n                    Assistant\n                  \n                \n              \n        \n            \n                \n                  \n                    \n                  \n                  \n                    \n                      Alina Potemkina\n                    \n                    Assistant\n                  \n                \n              \n        \n            \n                \n                  \n                    \n                  \n                  \n                    \n                      Oleg Kurilov\n                    \n                    Assistant\n                  \n                \n              \n        \n            \n                \n                  \n                    \n                  \n                  \n                    \n                      Sabina\n                    \n                    Assistant\n                  \n                \n              \n        \n            \n                \n                  \n                    \n                  \n                  \n                    \n                      Svetlana Mikhailova\n                    \n                    Assistant\n                  \n                \n              \n        \n    \n\n\nNo matching items"
  },
  {
    "objectID": "program.html",
    "href": "program.html",
    "title": "",
    "section": "",
    "text": "Class 1\n    \n        \n    \n    Вспоминаем линейную алгебру. Некоторые матричные разложения. Скорость сходимости. Одномерная оптимизация. Неточная одномерная оптимизация.\n\n    Class 2\n    \n        \n    \n    Градиент. Гессиан. Матрично-векторное дифференцирование. Автоматическое дифференцирование. Вычислительный граф.\n\n    Class 3\n    \n        \n    \n    Выпуклость. Выпуклые множества. Выпуклые функции. Неравенство Йенсена. Сильно выпуклые функции. Условие Поляка - Лоясиевича.\n\n    Class 4\n    \n        \n    \n    Условия оптимальности. Функция Лагранжа. Множители Лагранжа. Теорема Каруша - Куна - Таккера.\n\n    Class 5\n    \n        \n    \n    Двойственность. Введение в двойственность. Двойственная задача. Анализ чувствительности.\n\n    Class 6\n    \n        \n    \n    Задача линейного программирования. Симплекс метод.\n\n    Class 7\n    \n        \n    \n    Градиентный спуск. Теоремы сходимости в гладком случае (выпуклые, сильно выпуклые, PL). Верхние и нижние оценки сходимости.\n\n    Class 8\n    \n        \n    \n    Ускоренные градиентные методы. Метод Поляка, Нестерова.\n\n    Class 9\n    \n        \n    \n    Субградиент. Субдифференциал. Субградиентный спуск. Теоремы сходимости в негладком случае. Особенности работы градиентного метода в практических негладких задачах.\n\n    Class 10\n    \n        \n    \n    Метод сопряженных градиентов.\n\n    Class 11\n    \n        \n    \n    Проксимальный градиентный метод. Метод Франк-Вульфа. Метод проекции градиента.\n\n    Class 12\n    \n        \n    \n    Метод натурального градиента. Метод зеркального спуска. K-FAC.\n\n    Class 13\n    \n        \n    \n    Метод Ньютона. Квазиньютоновские методы.\n\n    Class 14\n    \n        \n    \n    Введение в методы внутренней точки.\n\n    Class 15\n    \n        \n    \n    Стохастический градиентный спуск. Адаптивные стохастические градиентные алгоритмы: AdaDelta, RMSProp, Adam, Nadam.\n\n    Class 16\n    \n        \n    \n    Методы редукции дисперсии: SAG, SVRG, SAGA.\n\n    Class 17\n    \n        \n    \n    Градиентный поток и диффузия. Методы оптимизации в непрерывном времени.\n\n    Class 18\n    \n        \n    \n    Седловые задачи. Минимакс. Обучение GAN.\n\n    Class 19\n    \n        \n    \n    Обобщающая способность моделей машинного обучения. Neural Tangent Kernel. Mode connectivity.\n\n    Class 20\n    \n        \n    \n    Вопросы обучения больших моделей. Lars, Lamb. Расписания learning rate. Warm-up. Клиппинг.\n\n\nNo matching items"
  }
]